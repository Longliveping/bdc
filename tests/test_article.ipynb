{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## db engine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from flask import Flask\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "basedir = os.path.abspath('..')\n",
    "app = Flask(__name__)\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'postgresql+psycopg2://localhost/test_db'\n",
    "app.config['SQLALCHEMY_COMMIT_ON_TEARDOWN'] = True\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "app.config['TESTING_FOLDER'] = os.path.join(basedir, 'utility/testing')\n",
    "app.config['MYDICT_FOLDER'] = os.path.join(basedir, 'utility/mydict')\n",
    "db = SQLAlchemy(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### db model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute '_set_parent_with_dispatch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-d37d71c60008>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 115\u001B[0;31m \u001B[0;32mclass\u001B[0m \u001B[0mMySentence\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mModel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    116\u001B[0m     \u001B[0m__tablename__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'mysentence'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    117\u001B[0m     \u001B[0mid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mColumn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mInteger\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprimary_key\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-2-d37d71c60008>\u001B[0m in \u001B[0;36mMySentence\u001B[0;34m()\u001B[0m\n\u001B[1;32m    116\u001B[0m     \u001B[0m__tablename__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'mysentence'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    117\u001B[0m     \u001B[0mid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mColumn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mInteger\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprimary_key\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 118\u001B[0;31m     \u001B[0msentence\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mColumn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0munique\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    119\u001B[0m     \u001B[0mtimestamp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mColumn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDateTime\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdefault\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdatetime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutcnow\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/sqlalchemy/sql/schema.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1375\u001B[0m                     \u001B[0mDefaultClause\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mserver_onupdate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfor_update\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1376\u001B[0m                 )\n\u001B[0;32m-> 1377\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_init_items\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1378\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1379\u001B[0m         \u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_creation_order\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/sqlalchemy/sql/schema.py\u001B[0m in \u001B[0;36m_init_items\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    105\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mitem\u001B[0m \u001B[0;32min\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mitem\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 107\u001B[0;31m                 \u001B[0mitem\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_set_parent_with_dispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    108\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    109\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_children\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'function' object has no attribute '_set_parent_with_dispatch'"
     ]
    }
   ],
   "source": [
    "class Article(db.Model):\n",
    "    __tablename__ = 'articles'\n",
    "\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    article = db.Column(db.String(256), unique=True)\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Article, self).__init__(**kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<Article:{self.id}-{self.article}>'\n",
    "\n",
    "class Sentence(db.Model):\n",
    "    __tablename__ = 'sentences'\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    sentence = db.Column(db.String(256))\n",
    "    translation = db.Column(db.String(256))\n",
    "    article_id = db.Column(db.Integer, db.ForeignKey('articles.id'))\n",
    "    article = db.relationship('Article', backref='sentences')\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Sentence, self).__init__(**kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<Sentence:{self.id}-{self.sentence}>'\n",
    "\n",
    "class Word(db.Model):\n",
    "    __tablename__ = 'words'\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    word = db.Column(db.String(64), unique=True)\n",
    "    translation = db.Column(db.String(256))\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Word, self).__init__(**kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<Word:{self.id}-{self.word}>'\n",
    "\n",
    "class SentenceWord(db.Model):\n",
    "    __tablename__ = 'sentencewords'\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    sentence_id = db.Column(db.Integer, db.ForeignKey('sentences.id'))\n",
    "    word_id = db.Column(db.Integer, db.ForeignKey('words.id'))\n",
    "    sentence = db.relationship('Sentence', backref='sentencewords')\n",
    "    word = db.relationship('Word', backref='sentencewords')\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SentenceWord, self).__init__(**kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<SentenceWord:{self.id}-{self.sentence}-{self.word}>'\n",
    "\n",
    "class ArticleWord(db.Model):\n",
    "    __tablename__ = 'articlewords'\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    article_id = db.Column(db.Integer, db.ForeignKey('articles.id'))\n",
    "    word_id = db.Column(db.Integer, db.ForeignKey('words.id'))\n",
    "    article = db.relationship('Article', backref='articlewords')\n",
    "    word = db.relationship('Word', backref='articlewords')\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ArticleWord, self).__init__(**kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<ArticleWord:{self.id}-{self.article}-{self.word}>'\n",
    "\n",
    "class SentenceReview(db.Model):\n",
    "    __tablename__ = 'sentencereviews'\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    sentence_id = db.Column(db.Integer, db.ForeignKey('sentences.id'))\n",
    "    noshow = db.Column(db.Boolean, default=False)\n",
    "    known = db.Column(db.Boolean, default=False)\n",
    "    unknown = db.Column(db.Boolean, default=True)\n",
    "    blurry = db.Column(db.Boolean, default=False)\n",
    "    review_timestamp = db.Column(db.DateTime, default=datetime.utcnow,onupdate=datetime.now())\n",
    "    sentence = db.relationship('Sentence', backref='sentencereviews')\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SentenceReview, self).__init__(**kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<SentenceReview:{self.id}-{self.sentence}>'\n",
    "\n",
    "class ArticleWordReview(db.Model):\n",
    "    __tablename__ = 'articlewordreviews'\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    artilceword_id = db.Column(db.Integer, db.ForeignKey('articlewords.id'))\n",
    "    noshow = db.Column(db.Boolean, default=False)\n",
    "    known = db.Column(db.Boolean, default=False)\n",
    "    unknown = db.Column(db.Boolean, default=True)\n",
    "    blurry = db.Column(db.Boolean, default=False)\n",
    "    review_timestamp = db.Column(db.DateTime, default=datetime.utcnow,onupdate=datetime.now())\n",
    "    articleword = db.relationship('ArticleWord', backref='articlewordreview')\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ArticleWordReview, self).__init__(**kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<ArticleWordReview:{self.id}-{self.word}>'\n",
    "\n",
    "class MyWord(db.Model):\n",
    "    __tablename__ = 'myword'\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    word = db.Column(db.String(64), unique=True)\n",
    "    timestamp = db.Column(db.DateTime, default=datetime.utcnow)\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyWord, self).__init__(**kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<MyWord:{self.id}-{self.word}>'\n",
    "\n",
    "\n",
    "class MySentence(db.Model):\n",
    "    __tablename__ = 'mysentence'\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    sentence = db.Column(db.text, unique=True)\n",
    "    timestamp = db.Column(db.DateTime, default=datetime.utcnow)\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MySentence, self).__init__(**kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<MySentence:{self.id}-{self.sentence}>'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Query\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT sentences.sentence AS sentences_sentence \n",
      "FROM sentences JOIN sentencewords ON sentences.id = sentencewords.sentence_id JOIN words ON words.id = sentencewords.word_id JOIN articles ON articles.id = sentences.article_id \n",
      "WHERE articles.article = %(article_1)s AND words.word = %(word_1)s\n"
     ]
    },
    {
     "data": {
      "text/plain": "[\"Scene: Chandler and Joey's, Chandler is helping Joey rehearse for a part.]\",\n 'Look, do you wanna get this part, or not?']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(db.session.query(Sentence.sentence).join(SentenceWord).join(Word).join(Article).filter(\n",
    "    Article.article == '103_The_One_With_the_Thumb',\n",
    "    Word.word == 'you'\n",
    "))\n",
    "\n",
    "ss = db.session.query(Sentence.sentence).join(SentenceWord).join(Word).join(Article).filter(\n",
    "        Article.article == '103_The_One_With_the_Thumb',\n",
    "        Word.word == 'part'\n",
    "    ).all()\n",
    "sentences = [s[0] for s in ss]\n",
    "sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### define functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_sentence(file):\n",
    "    with open(file, 'r') as f:\n",
    "        text = f.read()\n",
    "    pttn = re.compile(r\"[a-zA-Z].*\", re.I)\n",
    "    sentences = re.findall(pttn, text)\n",
    "    return sentences\n",
    "\n",
    "def get_tokens(text):\n",
    "    tokens = re.findall('[a-z]+', text.lower())\n",
    "    token = list(dict.fromkeys(tokens))\n",
    "    return token\n",
    "\n",
    "def read_text(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "def delete_table_records():\n",
    "    db.session.query(SentenceWord).delete()\n",
    "    db.session.query(Sentence).delete()\n",
    "    db.session.query(Word).delete()\n",
    "    db.session.query(Article).delete()\n",
    "    db.session.commit()\n",
    "\n",
    "def drop_everything():\n",
    "    \"\"\"(On a live db) drops all foreign key constraints before dropping all tables.\n",
    "    Workaround for SQLAlchemy not doing DROP ## CASCADE for drop_all()\n",
    "    (https://github.com/pallets/flask-sqlalchemy/issues/722)\n",
    "    \"\"\"\n",
    "    from sqlalchemy.engine.reflection import Inspector\n",
    "    from sqlalchemy.schema import DropConstraint, DropTable, MetaData, Table\n",
    "    con = db.engine.connect()\n",
    "    print(con)\n",
    "    trans = con.begin()\n",
    "    inspector = Inspector.from_engine(db.engine)\n",
    "\n",
    "    # We need to re-create a minimal metadata with only the required things to\n",
    "    # successfully emit drop constraints and tables commands for postgres (based\n",
    "    # on the actual schema of the running instance)\n",
    "    meta = MetaData()\n",
    "    tables = []\n",
    "    all_fkeys = []\n",
    "\n",
    "    for table_name in inspector.get_table_names():\n",
    "        fkeys = []\n",
    "\n",
    "        for fkey in inspector.get_foreign_keys(table_name):\n",
    "            if not fkey[\"name\"]:\n",
    "                continue\n",
    "\n",
    "            fkeys.append(db.ForeignKeyConstraint((), (), name=fkey[\"name\"]))\n",
    "\n",
    "        tables.append(Table(table_name, meta, *fkeys))\n",
    "        all_fkeys.extend(fkeys)\n",
    "\n",
    "    for fkey in all_fkeys:\n",
    "        con.execute(DropConstraint(fkey))\n",
    "\n",
    "    for table in tables:\n",
    "        con.execute(DropTable(table))\n",
    "\n",
    "    trans.commit()\n",
    "\n",
    "def import_articles(file):\n",
    "    basename = os.path.basename(file)\n",
    "    filename = basename.split('.')[0]\n",
    "    a1 = Article(article=filename)\n",
    "    db.session.add(a1)\n",
    "    db.session.commit()\n",
    "\n",
    "def get_file_by_type(filetype):\n",
    "    sourcedir = app.config.get('TESTING_FOLDER')\n",
    "    for basename in os.listdir(sourcedir):\n",
    "        file = os.path.join(sourcedir, basename)\n",
    "        basename = os.path.basename(file)\n",
    "        extention = basename.split('.')[1]\n",
    "        if extention == filetype:\n",
    "            return file\n",
    "\n",
    "def get_file_by_name(filename):\n",
    "    sourcedir = app.config.get('TESTING_FOLDER')\n",
    "    for basename in os.listdir(sourcedir):\n",
    "        file = os.path.join(sourcedir, basename)\n",
    "        basename = os.path.basename(file)\n",
    "        if basename.startswith(filename):\n",
    "            return file\n",
    "    return file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import time\n",
    "class Timer:\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, value, tb):\n",
    "        self.duration = time.time() - self.start"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create table\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "delete_table_records()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "db.drop_all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "db.create_all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### import article data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import_articles(get_file_by_name('103_'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# db.session.query(Article).delete()\n",
    "# db.session.commit()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tring"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# db.session.remove()\n",
    "# tokens = get_tokens(read_text(get_file('txt')))\n",
    "# words = [Word(word=t) for t in tokens]\n",
    "# db.session.add_all(words)\n",
    "# db.session.commit()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# sentences = get_sentence(get_file('txt'))\n",
    "# sentence = Sentence(sentence=sentences[0])\n",
    "# tokens = get_tokens(sentences[0])\n",
    "# words = [Word(word=t) for t in tokens]\n",
    "# sw = [SentenceWord(sentence=sentence, word=w) for w in words]\n",
    "#\n",
    "# db.session.add_all(sw)\n",
    "# db.session.new\n",
    "# db.session.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# db.session.remove()\n",
    "# sentence = 'this is a one'\n",
    "# tokens = get_tokens(sentence)\n",
    "# a = db.session.query(Article).first()\n",
    "# w1 = db.session.query(Word).filter(Word.word == tokens[0]).first()\n",
    "# w2 = db.session.query(Word).filter(Word.word == tokens[1]).first()\n",
    "# w3 = db.session.query(Word).filter(Word.word == tokens[2]).first()\n",
    "# w4 = db.session.query(Word).filter(Word.word == tokens[3]).first()\n",
    "# s = Sentence(sentence=sentence, article=a)\n",
    "# sw1 = SentenceWord(word=w1)\n",
    "# sw2 = SentenceWord(word=w2)\n",
    "# sw3 = SentenceWord(word=w3)\n",
    "# sw4 = SentenceWord(word=w4)\n",
    "# s.sentencewords.append(sw1)\n",
    "# s.sentencewords.append(sw2)\n",
    "# s.sentencewords.append(sw3)\n",
    "# s.sentencewords.append(sw4)\n",
    "# db.session.add(s)\n",
    "# db.session.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### import words avoiding Duplicates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.7895591259002686 seconds\n"
     ]
    }
   ],
   "source": [
    "# insert article words\n",
    "def import_word(filename):\n",
    "    with Timer() as timer:\n",
    "        tokens = set(get_tokens(read_text(get_file_by_name(filename))))\n",
    "        exist = db.session.query(Word.word).all()\n",
    "        exist =  set([e[0] for e in exist])\n",
    "        not_exist = tokens - exist\n",
    "        for n in not_exist:\n",
    "            w = Word(word=n)\n",
    "            db.session.add(w)\n",
    "        db.session.new\n",
    "        db.session.commit()\n",
    "    print(\"took\", timer.duration, \"seconds\")\n",
    "\n",
    "db.session.remove()\n",
    "import_word('big')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### import sentence and sentenceword"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 2.2678542137145996 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": "1885"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def import_sentence(filename):\n",
    "    with Timer() as timer:\n",
    "        # insert SentenceWords\n",
    "        db.session.remove()\n",
    "        article = db.session.query(Article).first()\n",
    "\n",
    "        sl = []\n",
    "        sentences = get_sentence(get_file_by_name(filename))\n",
    "        tokens_all = get_tokens(read_text(get_file_by_name(filename)))\n",
    "        words_all = db.session.query(Word).filter(Word.word.in_(tokens_all)).all()\n",
    "        for sentence in sentences:\n",
    "            tokens = get_tokens(sentence)\n",
    "            s = Sentence(sentence=sentence, article=article)\n",
    "            w = [w for w in words_all if w.word in tokens]\n",
    "            sw = [SentenceWord(word=i) for i in w]\n",
    "            s.sentencewords = sw\n",
    "            sl.append(s)\n",
    "        db.session.add_all(sl)\n",
    "        db.session.commit()\n",
    "\n",
    "    print(\"took\", timer.duration, \"seconds\")\n",
    "\n",
    "db.session.remove()\n",
    "import_sentence('103_')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### import my dict\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 5.542737245559692 seconds\n"
     ]
    }
   ],
   "source": [
    "def import_dict():\n",
    "    sourcedir = app.config.get('MYDICT_FOLDER')\n",
    "    file = os.path.join(sourcedir, 'mydict.csv' )\n",
    "    with Timer() as timer:\n",
    "        tokens = get_tokens(read_text(file))\n",
    "        for t in tokens:\n",
    "            m = db.session.query(Word).join(Mydict).filter(Word.word==t).first()\n",
    "            if not m:\n",
    "                w = db.session.query(Word).filter(Word.word == t).first()\n",
    "                if not w:\n",
    "                    w = Word(word=t)\n",
    "                    m = Mydict(word=w)\n",
    "                    db.session.add(w)\n",
    "                    db.session.add(m)\n",
    "                else:\n",
    "                    m = Mydict(word=w)\n",
    "                    db.session.add(m)\n",
    "        db.session.new\n",
    "        db.session.commit()\n",
    "    print(\"took\", timer.duration, \"seconds\")\n",
    "\n",
    "import_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Querying Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### all() method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[<Article:1-103_The_One_With_the_Thumb>,\n <Article:2-103_The_One_With_the_Thumb>]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.session.query(Article).limit(10).all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "<Word:10000-dedicated>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.session.query(Word).get(10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.session.query(Sentence).limit(10).all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.session.query(SentenceWord).limit(10).all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[<Mydict:1-<Word:1-i>>, <Mydict:2-<Word:2-you>>, <Mydict:3-<Word:3-a>>]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.session.query(Mydict).limit(10).all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### join() method\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "4258"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.session.query(Word).join(Mydict).count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT words.id AS words_id, words.word AS words_word, words.translation AS words_translation \n",
      "FROM words \n",
      "WHERE words.word IN (%(word_1)s, %(word_2)s)\n"
     ]
    }
   ],
   "source": [
    "print(db.session.query(Word).filter(Word.word.in_(['Toby', 'Sarah'])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "[<Word:6-the>, <Word:78-one>]"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.session.remove()\n",
    "db.session.query(Word).filter(Word.word.in_(['the', 'one'])).all()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "772"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import distinct\n",
    "db.session.query(\n",
    "    Article, Word\n",
    ").join(Sentence).join(SentenceWord).join(Word).filter(\n",
    "    Article.id == 1,\n",
    ").distinct().count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "772"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wheres = db.session.query(\n",
    "            Article, Word.word\n",
    "        ).join(Sentence).join(SentenceWord).join(Word).filter(\n",
    "            Article.id == 1,\n",
    "        ).distinct().all()\n",
    "words = [a[1] for a in wheres]\n",
    "len(words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "['joy',\n 'felt',\n 'pagekeeping',\n 'recording',\n 'seventeen',\n 'notebook',\n 'chemists',\n 'pulls',\n 'mum',\n 'hangs',\n 'lamp',\n 'theodore',\n 'feeling',\n 'balls',\n 'woodwood',\n 'metal',\n 'distance',\n 'break',\n 'excuse',\n 'hospital',\n 'brutal',\n 'country',\n 'suicide',\n 'buddy',\n 'putin',\n 'divide',\n 'house',\n 'beautiful',\n 'cakes',\n 'war',\n 'lost',\n 'represent',\n 'increase',\n 'potato',\n 'body',\n 'our',\n 'cancel',\n 'pins',\n 'ah',\n 'carry',\n 'comb',\n 'trade',\n 'heights',\n 'list',\n 'inappropriate',\n 'lived',\n 'nods',\n 'jupiter',\n 'stream',\n 'degree',\n 'bursts',\n 'shutting',\n 'anyone',\n 'narrowest',\n 'babies',\n 'touching',\n 'violence',\n 'headed',\n 'cars',\n 'alright',\n 'yards',\n 'halfan',\n 'natural',\n 'amazing',\n 'lines',\n 'thursday',\n 'ofbody',\n 'factory',\n 'africa',\n 'lands',\n 'perk',\n 'fifths',\n 'football',\n 'came',\n 'stepped',\n 'sugar',\n 'bits',\n 'population',\n 'moscow',\n 'lemme',\n 'broke',\n 'red',\n 'kettle',\n 'hopefully',\n 'noooo',\n 'cycle',\n 'celled',\n 'policy',\n 'voluntarily',\n 'thin',\n 'backpack',\n 'wha',\n 'lotion',\n 'january',\n 'gas',\n 'ofit',\n 'july',\n 'de',\n 'swimmer',\n 'boyfriends',\n 'ismilk',\n 'dear',\n 'operation',\n 'shakes',\n 'before',\n 'silently',\n 'nuts',\n 'senses',\n 'problem',\n 'sick',\n 'san',\n 'alarm',\n 'pacing',\n 'obama',\n 'mmmm',\n 'supplies',\n 'night',\n 'lenny',\n 'didn',\n 'sandwich',\n 'pfft',\n 'learnt',\n 'discovery',\n 'candle',\n 'jelly',\n 'hearts',\n 'changing',\n 'given',\n 'questions',\n 'should',\n 'kittens',\n 'homeless',\n 'pints',\n 'teachers',\n 'attraction',\n 'metals',\n 'shaking',\n 'collar',\n 'towns',\n 'california',\n 'egypt',\n 'quiet',\n 'comfortable',\n 'addition',\n 'woooo',\n 'curiously',\n 'railroads',\n 'both',\n 'grains',\n 'daddy',\n 'flavors',\n 'rested',\n 'museum',\n 'hid',\n 'agency',\n 'hooks',\n 'most',\n 'delicious',\n 'beijing',\n 'painter',\n 'pagemuch',\n 'kingdom',\n 'deaf',\n 'tobacco',\n 'monthsseptember',\n 'still',\n 'vulnerable',\n 'deserve',\n 'hooohhh',\n 'smokes',\n 'actually',\n 'carpet',\n 'adore',\n 'going',\n 'game',\n 'music',\n 'puts',\n 'stunning',\n 'paper',\n 'popula',\n 'went',\n 'spaghetti',\n 'lighting',\n 'closer',\n 'toe',\n 'chi',\n 'heads',\n 'play',\n 'true',\n 'grew',\n 'winning',\n 'child',\n 'pelosi',\n 'arrives',\n 'frost',\n 'usewhen',\n 'proving',\n 'awkward',\n 'andcold',\n 'alan',\n 'language',\n 'yeah',\n 'follow',\n 'support',\n 'shoots',\n 'plays',\n 'whole',\n 'squares',\n 'feels',\n 'uniform',\n 'closeness',\n 'unite',\n 'grownups',\n 'dessert',\n 'swim',\n 'also',\n 'of',\n 'grass',\n 'happens',\n 'dora',\n 'button',\n 'flyball',\n 'proof',\n 'times',\n 'tries',\n 'trash',\n 'crazy',\n 'win',\n 'freaked',\n 'bing',\n 'indoor',\n 'pageour',\n 'uncooked',\n 'information',\n 'fist',\n 'mandarin',\n 'advance',\n 'carrying',\n 'wasn',\n 'shopping',\n 'useusesused',\n 'valve',\n 'liked',\n 'hesitates',\n 'boyfriend',\n 'together',\n 'cages',\n 'dark',\n 'nokululu',\n 'viii',\n 'closing',\n 'seek',\n 'sports',\n 'heated',\n 'ofmaking',\n 've',\n 'phew',\n 'learn',\n 'tax',\n 'goodbye',\n 'mother',\n 'other',\n 'entering',\n 'books',\n 'throat',\n 'cube',\n 'go',\n 'circle',\n 'seated',\n 'bus',\n 'phoebe',\n 'p',\n 'lightout',\n 'ground',\n 'ethan',\n 'wings',\n 'false',\n 'ifthe',\n 'eleven',\n 'reception',\n 'leaping',\n 'see',\n 'walking',\n 'pagebefore',\n 'loves',\n 'rack',\n 'eight',\n 'nation',\n 'cigarett',\n 'fallof',\n 'attracted',\n 'asked',\n 'post',\n 'dependent',\n 'shrug',\n 'pagethat',\n 'guys',\n 'sailed',\n 'checked',\n 'pageshe',\n 'saw',\n 'leaves',\n 'headphones',\n 'wheel',\n 'ther',\n 'you',\n 'interdependent',\n 'learned',\n 'age',\n 'dump',\n 'minnie',\n 'ofthings',\n 'swimming',\n 'though',\n 'ofblood',\n 'thumb',\n 'dates',\n 'putting',\n 'retailers',\n 'towel',\n 'dirty',\n 'figured',\n 'butterfat',\n 'pilot',\n 'closed',\n 'learner',\n 'pepper',\n 'roses',\n 'ofreaders',\n 'govern',\n 'trapped',\n 'village',\n 'thick',\n 'club',\n 'to',\n 'tosses',\n 'shorter',\n 'subway',\n 'inoutoutout',\n 'hah',\n 'near',\n 'your',\n 'an',\n 'burn',\n 'pagebraille',\n 'plastic',\n 'nose',\n 'friday',\n 'imagination',\n 'pouring',\n 'unwell',\n 'ofkeeping',\n 'calling',\n 'tree',\n 'november',\n 'unlike',\n 'eeps',\n 'watcher',\n 'indians',\n 'americans',\n 'weatherwhy',\n 'school',\n 'pin',\n 'isgoing',\n 'eyeing',\n 'wall',\n 'ofcell',\n 'skirt',\n 'ifyou',\n 'hate',\n 'mouse',\n 'pack',\n 'pauses',\n 'opponent',\n 'today',\n 'eat',\n 'matters',\n 'chances',\n 'offices',\n 'answering',\n 'sunny',\n 'fingers',\n 'reacts',\n 'nono',\n 'isin',\n 'misunderstanding',\n 'upper',\n 'structure',\n 'pageclocks',\n 'homes',\n 'detail',\n 'clears',\n 'grandchildren',\n 'triangle',\n 'angry',\n 'airplanes',\n 'golfing',\n 'invention',\n 'independence',\n 'he',\n 'decorate',\n 'shh',\n 'airplane',\n 'wound',\n 'squeeze',\n 'dogin',\n 'france',\n 'figment',\n 'regulations',\n 'exchange',\n 'extis',\n 'donald',\n 'puzzled',\n 'something',\n 'finish',\n 'weight',\n 'chewing',\n 'sticks',\n 'receipt',\n 'york',\n 'saltsugarbook',\n 'ofsteam',\n 'upside',\n 'pig',\n 'fahrenheit',\n 'monthsjune',\n 'blocked',\n 'coronavirus',\n 'mirror',\n 'underclothes',\n 'minimum',\n 'lie',\n 'delhi',\n 'drawings',\n 'letters',\n 'oops',\n 'control',\n 'has',\n 'emotional',\n 'jack',\n 'take',\n 'atall',\n 'under',\n 'group',\n 'thing',\n 'horsethis',\n 'whispers',\n 'word',\n 'uhhh',\n 'camera',\n 'covering',\n 'follows',\n 'pros',\n 'iam',\n 'fancy',\n 'century',\n 'monthsmarch',\n 'fire',\n 'choose',\n 'tom',\n 'drop',\n 'bear',\n 'but',\n 'giant',\n 'houses',\n 'flush',\n 'photo',\n 'grabbed',\n 'respond',\n 'ass',\n 'iced',\n 'else',\n 'route',\n 'sight',\n 'beyond',\n 'tuna',\n 'countries',\n 'having',\n 'espresso',\n 'box',\n 'everyone',\n 'obamacare',\n 'admitting',\n 'wouldn',\n 'way',\n 'ofan',\n 'quick',\n 'arrival',\n 'buzz',\n 'imaginary',\n 'vegetable',\n 'oldest',\n 'abouttwenty',\n 'handwriting',\n 'bridge',\n 'es',\n 'act',\n 'racist',\n 'bangs',\n 'animals',\n 'caff',\n 'art',\n 'ma',\n 'wanna',\n 'chain',\n 'yelling',\n 'uninterrupted',\n 'low',\n 'frannie',\n 'kids',\n 'sandals',\n 'away',\n 'reflect',\n 'mothers',\n 'including',\n 'dinosaur',\n 'sometoothpaste',\n 'nicely',\n 'tried',\n 'washington',\n 'ninth',\n 'foods',\n 'pageautomobiles',\n 'equalto',\n 'breaths',\n 'lengths',\n 'u',\n 'talking',\n 'handing',\n 'fried',\n 'toothless',\n 'four',\n 'happening',\n 'episode',\n 'nails',\n 'keys',\n 'nice',\n 'lot',\n 'letter',\n 'elbow',\n 'former',\n 'files',\n 'painting',\n 'watching',\n 'thousands',\n 'distracted',\n 'sale',\n 'gift',\n 'glue',\n 'title',\n 'dryer',\n 'melanie',\n 'earliest',\n 'magical',\n 'photosynthesis',\n 'pretty',\n 'itchy',\n 'wor',\n 'wait',\n 'sailing',\n 'wool',\n 'minds',\n 'nor',\n 'nearer',\n 'relax',\n 'honey',\n 'ceremony',\n 'ugh',\n 'zipper',\n 'watering',\n 'honeymoon',\n 'regional',\n 'depend',\n 'sleeve',\n 'father',\n 'awall',\n 'tiny',\n 'sorts',\n 'company',\n 'gathered',\n 'mainly',\n 'turtle',\n 'waaaay',\n 'photograph',\n 'familiar',\n 'weeks',\n 'socialized',\n 'cave',\n 'roof',\n 'good',\n 'tastes',\n 'bar',\n 'hook',\n 'aside',\n 'pretending',\n 'lightly',\n 'ask',\n 'schedule',\n 'right',\n 'words',\n 'brrr',\n 'dirtiest',\n 'smashed',\n 'drinking',\n 'port',\n 'withthe',\n 'bottles',\n 'possibly',\n 'statements',\n 'huh',\n 'throwing',\n 'fatherand',\n 'impression',\n 'picking',\n 'did',\n 'edges',\n 'scent',\n 'hers',\n 'poking',\n 'seemed',\n 'among',\n 'drifted',\n 'violated',\n 'fears',\n 'finds',\n 'thoroughly',\n 'singers',\n 'favor',\n 'pump',\n 'town',\n 'smith',\n 'sat',\n 'initial',\n 'ofhearing',\n 'gain',\n 'fit',\n 'measure',\n 'gin',\n 'chocolate',\n 'rocky',\n 'seems',\n 'draws',\n 'causes',\n 'diary',\n 'wiping',\n 'movie',\n 'metres',\n 'get',\n 'working',\n 'egging',\n 'does',\n 'beforehand',\n 'bringing',\n 'sense',\n 'never',\n 'larger',\n 'wating',\n 'members',\n 'sorry',\n 'rob',\n 'stunned',\n 'holidays',\n 'likes',\n 'burning',\n 'flames',\n 'comparing',\n 'rag',\n 'priestley',\n 'cowboys',\n 'reaching',\n 'rethink',\n 'adviser',\n 'because',\n 'fetch',\n 'burst',\n 'whatever',\n 'complain',\n 'zip',\n 'ofchanges',\n 'seven',\n 'snap',\n 'top',\n 'goes',\n 'answers',\n 'pee',\n 'meant',\n 'trees',\n 'walls',\n 'very',\n 'tons',\n 'cookie',\n 'second',\n 'me',\n 'comforting',\n 'congratulates',\n 'pffft',\n 'graph',\n 'anthony',\n 'thirty',\n 'decide',\n 'pastpresentfuture',\n 'fixating',\n 'envelope',\n 'smile',\n 'shocked',\n 'honest',\n 'weren',\n 'doin',\n 'breathe',\n 'mouthful',\n 'truck',\n 'puppies',\n 'skirta',\n 'factories',\n 'letput',\n 'ahf',\n 'seventeenth',\n 'space',\n 'turned',\n 'kicking',\n 'passionately',\n 'whether',\n 'faces',\n 'etc',\n 'shows',\n 'oh',\n 'telescope',\n 'division',\n 'garden',\n 'princess',\n 'wipe',\n 'normal',\n 'pagemrs',\n 'englishman',\n 'ofgovernment',\n 'quicker',\n 'ridiculous',\n 'catches',\n 'farting',\n 'stains',\n 'item',\n 'amazed',\n 'past',\n 'missed',\n 'background',\n 'even',\n 'brains',\n 'garbage',\n 'roy',\n 'yesterday',\n 'glass',\n 'adam',\n 'once',\n 'ofpaper',\n 'ballots',\n 'considered',\n 'cartoon',\n 'chant',\n 'greece',\n 'alcohol',\n 'workers',\n 'coincidence',\n 'halfa',\n 'dramas',\n 'cleaner',\n 'test',\n 'facts',\n 'wrong',\n 'ray',\n 'sister',\n 'transport',\n 'scientists',\n 'tin',\n 'andplates',\n 'voic',\n 'trading',\n 'simon',\n 'needy',\n 'hide',\n 'soon',\n 'different',\n 'jina',\n 'stoned',\n 'bob',\n 'carelessly',\n 'can',\n 'greet',\n 'longer',\n 'afternoon',\n 'lrr',\n 'newspapers',\n 'temperatures',\n 'public',\n 'rat',\n 'knock',\n 'rid',\n 'if',\n 'serve',\n 'helped',\n 'graphein',\n 'shelf',\n 'millions',\n 'angle',\n 'whose',\n 'ifthere',\n 'buying',\n 'bin',\n 'intelligent',\n 'rice',\n 'history',\n 'angela',\n 'emergency',\n 'gestures',\n 'feathers',\n 'cool',\n 'rush',\n 'learning',\n 'raining',\n 'grocery',\n 'heatwhich',\n 'laughed',\n 'smiling',\n 'enough',\n 'gums',\n 'effect',\n 'cocktails',\n 'do',\n 'dishwasher',\n 'husbands',\n 'stamp',\n 'pagebecause',\n 'barbecue',\n 'expression',\n 'was',\n 'moon',\n 'controlling',\n 'east',\n 'invited',\n 'rectangle',\n 'nicer',\n 'arm',\n 'tion',\n 'beef',\n 'count',\n 'wider',\n 'king',\n 'mississippi',\n 'discover',\n 'attractive',\n 'accounts',\n 'sixty',\n 'tomorrow',\n 'meter',\n 'sexy',\n 'depressed',\n 'apartment',\n 'presents',\n 'watch',\n 'oil',\n 'hell',\n 'stop',\n 'growth',\n 'doorsof',\n 'meet',\n 'sees',\n 'twist',\n 'billy',\n 'wild',\n 'pumps',\n 'warden',\n 'goods',\n 'nodding',\n 'eats',\n 'english',\n 'team',\n 'smelling',\n 'okay',\n 'freezer',\n 'ni',\n 'religion',\n 'dad',\n 'yard',\n 'somebody',\n 'published',\n 'valentine',\n 'doctor',\n 'mostly',\n 'damage',\n 'spicy',\n 'openthis',\n 'ofthemselves',\n 'sobbing',\n 'controlled',\n 'chase',\n 'ouch',\n 'restaurants',\n 'barrett',\n 'max',\n 'persons',\n 'senator',\n 'rules',\n 'gallons',\n 'photographs',\n 'automobile',\n 'sweater',\n 'field',\n 'burns',\n 'newspaper',\n 'jet',\n 'soul',\n 'yes',\n 'shown',\n 'business',\n 'plus',\n 'studies',\n 'eventually',\n 'fires',\n 'united',\n 'raise',\n 'ringing',\n 'vendor',\n 'meeting',\n 'frame',\n 'nervously',\n 'pours',\n 'bridesmaids',\n 'grace',\n 'kilogram',\n 'wrote',\n 'ofmilk',\n 'reluctantly',\n 'spit',\n 'stay',\n 'realize',\n 'andthree',\n 'section',\n 'mindy',\n 'loosely',\n 'cookies',\n 'pink',\n 'veryvery',\n 'when',\n 'fingeron',\n 'starting',\n 'lives',\n 'myself',\n 'behind',\n 'least',\n 'practically',\n 'sunday',\n 'long',\n 'branching',\n 'caught',\n 'minute',\n 'luggage',\n 'than',\n 'or',\n 'woke',\n 'wallace',\n 'plate',\n 'passion',\n 'experiment',\n 'sweet',\n 'jump',\n 'discoveries',\n 'sixth',\n 'gotsent',\n 'shave',\n 'einstein',\n 'carries',\n 'i',\n 'december',\n 'administration',\n 'tions',\n 'borders',\n 'slow',\n 'teeth',\n 'pound',\n 'decisions',\n 'whites',\n 'reaction',\n 'thinner',\n 'powder',\n 'metron',\n 'bound',\n 'ofwork',\n 'sharpen',\n 'queen',\n 'moonlight',\n 'scary',\n 'thanthin',\n 'again',\n 'bra',\n 'ofnew',\n 'injured',\n 'moonis',\n 'automatic',\n 'city',\n 'amounts',\n 'why',\n ...]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myword = db.session.query(MyWord.word).all()\n",
    "mywords = ([w[0] for w in myword])\n",
    "mywords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT words.word AS words_word \n",
      "FROM words JOIN articlewords ON words.id = articlewords.word_id JOIN articles ON articles.id = articlewords.article_id \n",
      "WHERE articles.article = %(article_1)s AND words.word NOT IN (%(word_1)s, %(word_2)s)\n"
     ]
    }
   ],
   "source": [
    "print( db.session.query(Word.word).join(ArticleWord).join(Article).filter(\n",
    "        Article.article == '103_The_One_With_the_Thumb',\n",
    "        Word.word.notin_(mywords[:2])\n",
    "    ))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-c48ba242",
   "language": "python",
   "display_name": "PyCharm (sqlalchemy-1)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}